{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2d: Goals and Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goals of this assignment are:\n",
    "* To review basic NLP tasks for words using dictionaries, lists and file read/write. We will focus especially on *counting* things.\n",
    "* To make some basic corpus-level visualizations.\n",
    "\n",
    "Here are the steps you should do to successfully complete this project:\n",
    "1. From moodle, accept the assignment. Open and set up a code space (install a python kernal and select it).\n",
    "2. Complete the notebook and commit it to Github. Make sure to answer all questions, and to commit the notebook in a \"run\" state!\n",
    "3. I wrote the comments; you write the code! Complete and run `spacy_on_corpus.py` following the instructions in this notebook.\n",
    "4. Edit the README.md file. Provide your name, your class year, links to/descriptions of any extensions and a list of resources. \n",
    "5. Commit your code often. We will take the last commit before the deadline as your submission of the project.\n",
    "\n",
    "Possible extensions (from least points to most points):\n",
    "* Make word counts plots for the top 100 words and entities. Look at the labels on the y axis of each plot. Where do you think spaCy is making mistakes?\n",
    "* Augment the `wordcount` functionality so that it displays relative frequencies of entity label pairs and token part of speech pairs.\n",
    "* Learn about the useful python collections package, especially the [Counter data type](https://docs.python.org/3/library/collections.html#collections.Counter). Copy spacy_on_corpus.py and name the copy spacy_on_corpus-counter.py. Change `get_token_counts` and `get_entity_counts` to use counters. \n",
    "* Add in the analyses from project 2c as functions `make_doc_markdown`, `make_doc_tables` and `make_doc_stats`; make sure to ask the user for a document before running any of these!\n",
    "* Your other ideas are welcome! If you'd like to discuss one with Dr Stent, feel free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Our Packages\n",
    "\n",
    "On the command line (in the terminal), type:\n",
    "\n",
    "% `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Our Data\n",
    "\n",
    "From Moodle, download `files.zip`. \n",
    "\n",
    "Then, upload `files.zip` to the code space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Sure We Can Work With .py Files We Are Editing\n",
    "\n",
    "Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Better Python Code: Functions\n",
    "\n",
    "Last week we wrote a really long python script (many lines of code)! But what if we want to reuse some code somewhere else? Then we have to copy it, and if it has a mistake we'll have to fix the bug in both places. Also, really long python scripts are very hard to understand.\n",
    "\n",
    "To write code that is easier to understand and more reusable, we use **encapsulation**. Specifically, in this project we will start to write and use our own python **functions**. We will write functions to analyze a whole corpus.\n",
    "\n",
    "Here is a sample python function:\n",
    "```\n",
    "def length(input_text):\n",
    "   print(f'length is %i' % len(input_text))\n",
    "   return len(input_text) \n",
    "```\n",
    "\n",
    "A function **definition** in python assigns a variable name to a code block:\n",
    "* `def` tells you we are defining a function here\n",
    "* `length` is the variable we will assign to the code block\n",
    "* `input_text` is an **argument** (or **parameter**) to this function\n",
    "* the code block inside this function is two lines long; it prints the length, and then it returns the length\n",
    "* this function **returns** a value, the length of the input text; functions do not have to return a value but many do\n",
    "\n",
    "Once you have defined a function you can can **call** (or use) it in other places. \n",
    "\n",
    "Every function you have learned about so far this semester is defined either in 'core' python, or in a python package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do want to comment our functions. We do this using a **docstring**. The docstring tells readers: what the function does; what the arguments mean, and what the return value should look like (if any). The docstring is set off with three quotes (\"\"\") at start and end. \n",
    "\n",
    "```\n",
    "def length(input_text):\n",
    "   \"\"\"Calculates the length of the input input_text.\n",
    "      :param input_text: some text\n",
    "      :type input_text: string\n",
    "      :returns: the length of input_text\n",
    "      :rtype: int\n",
    "   \"\"\"\n",
    "   print(f'length is %i' % len(input_text))\n",
    "   return len(input_text)\n",
    "```\n",
    "\n",
    "We will write a docstring in this format for every function we define. Sometimes, this may mean we do not need to write a comment for every line of code! (However, for project 2d I give you a comment for almost every line of code.)\n",
    "\n",
    "You can learn more about python docstrings [here](https://realpython.com/documenting-python-code/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions in Notebooks\n",
    "\n",
    "You can define a python function in a notebook code cell, and then use it. In the code cell below, paste the `length` function definition from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste the definition of the length() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call length on the text 'This is a test!'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get this output:\n",
    "```\n",
    "length is 15\n",
    "15\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions in Python Files\n",
    "\n",
    "More usually, we store functions in `.py` files. Then we can import the `.py` file and call the functions in it.\n",
    "\n",
    "Create a new file called `test_functions.py`. Paste the definition of the `length` function in it. \n",
    "\n",
    "In the code cell below, import `test_functions.py` like this: `import test_functions` (you don't need to specify `.py`. \n",
    "\n",
    "Then call the function `length` as defined in `test_functions`. You do this like: `test_functions.length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from test_functions.py\n",
    "\n",
    "# call length on the text 'This is another test!'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get this output:\n",
    "```\n",
    "length is 21\n",
    "21\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Functions in spacy_on_corpus.py\n",
    "\n",
    "For this project, I have given you a file `spacy_on_corpus.py`. You will fill in the functions and test them in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will need a test corpus. I give you one here (the text for each document comes from the Wikipedia page for the named college or university)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "\n",
    "# import pprint\n",
    "\n",
    "\n",
    "# make a spacy engine\n",
    "\n",
    "# make a corpus\n",
    "corpus = {'doc1': {'text': 'Colby College is a private liberal arts college in Waterville, Maine. Founded in 1813 as the Maine Literary and Theological Institution, it was renamed Waterville College in 1821. The donations of Christian philanthropist Gardner Colby saw the institution renamed again to Colby University before settling on its current title, reflecting its liberal arts college curriculum, in 1899. Approximately 2,000 students from more than 60 countries are enrolled annually. The college offers 54 major fields of study and 30 minors. Located in central Maine, the 714-acre Neo-Georgian campus sits atop Mayflower Hill and overlooks downtown Waterville and the Kennebec River Valley. Along with fellow Maine institutions Bates College and Bowdoin College, Colby competes in the New England Small College Athletic Conference (NESCAC) and the Colby-Bates-Bowdoin Consortium.'},\n",
    "          'doc2': {'text': 'Columbia University, officially titled as Columbia University in the City of New York, is a private Ivy League research university in New York City. Established in 1754 as King\\'s College on the grounds of Trinity Church in Manhattan, it is the oldest institution of higher education in New York and the fifth-oldest in the United States.'}}\n",
    "\n",
    "# run spacy on each text in the corpus\n",
    "for key in corpus:\n",
    "    corpus[key]['doc'] = nlp(corpus[key]['text'])\n",
    "\n",
    "# print the corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `get_token_counts`\n",
    "\n",
    "Complete the implementation of `get_token_counts` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `get_token_counts` on the provided corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy_on_corpus\n",
    "\n",
    "\n",
    "# call get_token_counts on corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should start with:\n",
    "```\n",
    "[('Colby', 5),\n",
    " ('College', 6),\n",
    " ('is', 3),\n",
    " ('a', 2),\n",
    " ('private', 2),\n",
    " ('liberal', 2),\n",
    " ('arts', 2),\n",
    " ('college', 3),\n",
    " ('in', 12),\n",
    " ('Waterville', 3),\n",
    " ('Maine', 4),\n",
    " ('Founded', 1),\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function has some **optional arguments**. Look at the function **signature** (the line that starts with `def`). See that there are two arguments, but one of them has a value assigned to it already (using `=`). That means, if you don't want to say what the tags to exclude should be, you can take the default ones specified in the signature. \n",
    "\n",
    "Let's try changing this. Let's make *no* tags excluded.\n",
    "\n",
    "In the code cell below, run `get_token_counts` on the corpus provided, also specifying `tags_to_exclude = []` (the empty list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call get_token_counts with no tags to exclude\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should start with:\n",
    "```\n",
    "[('Colby', 5),\n",
    " ('College', 6),\n",
    " ('is', 3),\n",
    " ('a', 2),\n",
    " ('private', 2),\n",
    " ('liberal', 2),\n",
    " ('arts', 2),\n",
    " ('college', 3),\n",
    " ('in', 12),\n",
    " ('Waterville', 3),\n",
    " (',', 9),\n",
    " ('Maine', 4),\n",
    " ('.', 9),\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, referring to [the coarse-grained tag list](https://universaldependencies.org/u/pos/all.html), what do you have to do to make `get_token_counts` *only* give you counts of (proper or regular) nouns, verbs, adjectives and adverbs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call get_token_counts excluding all tags but those corresponding to nouns, verbs, adjectives and adverbs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should start with:\n",
    "```\n",
    "[('Colby', 5),\n",
    " ('College', 6),\n",
    " ('private', 2),\n",
    " ('liberal', 2),\n",
    " ('arts', 2),\n",
    " ('college', 3),\n",
    " ('Waterville', 3),\n",
    " ('Maine', 4),\n",
    " ('Founded', 1),\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `get_entity_counts`\n",
    "\n",
    "Complete the implementation of `get_entity_counts` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `get_entity_counts` on the provided corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# call get_entity_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should start with:\n",
    "```\n",
    "[('Colby College', 1),\n",
    " ('Waterville', 2),\n",
    " ('Maine', 3),\n",
    " ('1813', 1),\n",
    " ('the Maine Literary and Theological Institution', 1),\n",
    " ('Waterville College', 1),\n",
    " ('1821', 1),\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, referring to [the spaCy model docs](https://spacy.io/models/en), what do you have to do to make `get_entity_counts` *only* give you organizations, persons and locations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call get_entity_counts so as to get only organizations, persons and locations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should start with:\n",
    "```\n",
    "[('Colby College', 1),\n",
    " ('Waterville', 2),\n",
    " ('Maine', 3),\n",
    " ('the Maine Literary and Theological Institution', 1),\n",
    " ('Waterville College', 1),\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `reduce_to_top_k`\n",
    "\n",
    "Complete the implementation of `reduce_to_top_k` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `reduce_to_top_k` on the output of `get_token_counts` on the provided corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# get the token counts on corpus; assign token_counts to the returned result\n",
    "token_counts = \n",
    "\n",
    "# call reduce_to_top_k on token_counts to get the top 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like:\n",
    "```\n",
    "[('of', 5), ('College', 6), ('and', 7), ('the', 11), ('in', 12)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `load_textfile`\n",
    "\n",
    "Complete the implementation of `load_textfile` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `load_textfile` on 'colby_college.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# initialize corpus to the empty dictionary\n",
    "\n",
    "# call load_textfile\n",
    "\n",
    "# print corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like:\n",
    "```\n",
    "{'colby_college.txt': {'doc': Colby College is a private liberal arts college in Waterville, Maine. Founded in 1813 as the Maine Literary and Theological Institution, it was renamed Waterville College in 1821. The donations of Christian philanthropist Gardner Colby saw the institution renamed again to Colby University before settling on its current title, reflecting its liberal arts college curriculum, in 1899. Approximately 2,000 students from more than 60 countries are enrolled annually. The college offers 54 major fields of study and 30 minors.\n",
    " \n",
    " Located in central Maine, the 714-acre Neo-Georgian campus sits atop Mayflower Hill and overlooks downtown Waterville and the Kennebec River Valley. Along with fellow Maine institutions Bates College and Bowdoin College, Colby competes in the New England Small College Athletic Conference (NESCAC) and the Colby-Bates-Bowdoin Consortium.\n",
    "}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `load_compressed`\n",
    "\n",
    "Complete the implementation of `load_compressed` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `load_compressed` on 'files.zip'. (This may take a little while!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# initialize corpus to the empty dictionary\n",
    "\n",
    "# call load_compressed\n",
    "\n",
    "# print corpus keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like:\n",
    "```\n",
    "dict_keys(['temp/ark:__27927_pjb5s37cx32', 'temp/ark:__27927_phx1wcjq0tm', 'temp/ark:__27927_phzmmfj893c', 'temp/ark:__27927_phzkfzqzs41', 'temp/ark:__27927_phzq8c34ggp', 'temp/ark:__27927_pjb3ptfm8xd', 'temp/ark:__27927_phz8qhfbxzm', 'temp/ark:__27927_pjb1wn175cv', 'temp/ark:__27927_phznswfkrxz', 'temp/ark:__27927_pjb65xt4m6r', 'temp/ark:__27927_phzq26wnjzn', 'temp/ark:__27927_phzbjns29gn', 'temp/ark:__27927_phzpdcpvdnb', 'temp/ark:__27927_pjb1z8505hp', 'temp/ark:__27927_phz35174v0z', 'temp/ark:__27927_phzjj6kfdxp', 'temp/ark:__27927_pjb16g9m9r7', 'temp/ark:__27927_pjb1z5xzrx7'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `build_corpus`\n",
    "\n",
    "Complete the implementation of `build_corpus` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `build_corpus` on the pattern 'c*.txt'.\n",
    "\n",
    "Note, `build_corpus` _returns a corpus_, so you want to assign that return value to a variable (like `my_corpus`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# call load_compressed\n",
    "\n",
    "# print corpus keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like:\n",
    "```\n",
    "dict_keys(['colby_college.txt', 'columbia_university.txt'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `get_basic_statistics`\n",
    "\n",
    "Complete the implementation of `get_basic_statistics` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `get_basic_statistics` on the given corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# call load_compressed\n",
    "\n",
    "# call get_basic_statistics on my_corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look like:\n",
    "```\n",
    "Documents: 2\n",
    "\n",
    "Tokens: 187\n",
    "\n",
    "Unique tokens: 115\n",
    "\n",
    "Entities: 187\n",
    "\n",
    "Unique entities: 33\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `plot_word_entity_frequencies`\n",
    "\n",
    "Complete the implementation of `plot_word_entity_frequencies` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `plot_word_entity_frequencies` on the given corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# call load_compressed\n",
    "\n",
    "# call get_basic_statistics on my_corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting file `token_counts.png` should look like:\n",
    "\n",
    "![token_counts.png](answer_token_counts.png)\n",
    "\n",
    "The resulting file `entity_counts.png` should look like:\n",
    "\n",
    "![token_counts.png](answer_entity_counts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `plot_word_cloud`\n",
    "\n",
    "Complete the implementation of `plot_word_cloud` in `spacy_on_corpus.py`. \n",
    "\n",
    "Then, in the code cell below import `spacy_on_corpus` and run `plot_word_cloud` on the given corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "# call load_compressed\n",
    "\n",
    "# call get_basic_statistics on my_corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "he resulting file `token_counts.png` should look like:\n",
    "\n",
    "![token_wordcloud.png](answer_token_wordcloud.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running `spacy_on_corpus.py` from the Terminal\n",
    "\n",
    "Complete the implementation of `main` in `spacy_on_corpus.py`. \n",
    "\n",
    "Now run this in the terminal:\n",
    "% `python spacy_on_corpus.py`\n",
    "\n",
    "Give it `files.zip` as the pattern. Get all of 'statistics', 'wordcount' and 'wordcloud'.\n",
    "\n",
    "Insert the 'wordcount' images and 'wordcloud' image generated when you run it.\n",
    "\n",
    "## Token count plot\n",
    "\n",
    "\n",
    "## Entity count plot\n",
    "\n",
    "\n",
    "## Word cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. *Name a core python function that _does not_ return a value*:\n",
    "2. *Name a core python function that _does_ return a value*:\n",
    "3. *What is the structure of each entry in `corpus`?* For example, is a list of sets of strings, or a dict of lists of ints, or...?\n",
    "4. *How many tokens and unique tokens are in the corpus defined by `files.zip`?*\n",
    "5. *How many entities and unique entities are in the corpus defined by `files.zip`?*\n",
    "6. *How many arguments does `build_corpus` have?*\n",
    "7. *What is the structure of the return value from `reduce_to_top_k`?*\n",
    "8. *How can you make *sorted* reverse sort (from largest to smallest)?* You can refer to the python documentation.\n",
    "9. *How can you modify the code so that the word cloud that is generated doesn't just contain uninteresting words like 'a' and 'and'?*\n",
    "10. *Once you have answered question 9, from looking at the word cloud what do you think are some themes of this corpus?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Isn't the code in spacy_on_corpus.py easier to follow than the code from project 2c??**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
